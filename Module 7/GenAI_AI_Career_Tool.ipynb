{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_rsVAp4N8k0z",
        "outputId": "6862a4b3-ac54-4237-e3b8-a2281a8457c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==4.17.0\n",
            "  Downloading gradio-4.17.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting ibm-watson-machine-learning==1.0.349\n",
            "  Downloading ibm_watson_machine_learning-1.0.349-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting email-validator==2.1.1\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.17.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (4.2.2)\n",
            "Collecting fastapi (from gradio==4.17.0)\n",
            "  Downloading fastapi-0.114.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==4.17.0)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==0.9.0 (from gradio==4.17.0)\n",
            "  Downloading gradio_client-0.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx (from gradio==4.17.0)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (0.24.6)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio==4.17.0)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (2.9.1)\n",
            "Collecting pydub (from gradio==4.17.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==4.17.0)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (6.0.2)\n",
            "Collecting ruff>=0.1.7 (from gradio==4.17.0)\n",
            "  Downloading ruff-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==4.17.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.17.0)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.17.0) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.17.0) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.17.0)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ibm-watson-machine-learning==1.0.349) (2.32.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from ibm-watson-machine-learning==1.0.349) (2.0.7)\n",
            "Collecting pandas<3.0,>=1.0 (from gradio==4.17.0)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from ibm-watson-machine-learning==1.0.349) (2024.8.30)\n",
            "Collecting lomond (from ibm-watson-machine-learning==1.0.349)\n",
            "  Downloading lomond-0.3.3-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ibm-watson-machine-learning==1.0.349) (0.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from ibm-watson-machine-learning==1.0.349) (8.5.0)\n",
            "Collecting ibm-cos-sdk<2.14.0,>=2.12.0 (from ibm-watson-machine-learning==1.0.349)\n",
            "  Downloading ibm-cos-sdk-2.13.6.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dnspython>=2.0.0 (from email-validator==2.1.1)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator==2.1.1) (3.8)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.9.0->gradio==4.17.0) (2024.6.1)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.9.0->gradio==4.17.0)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.17.0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.17.0) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.17.0) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.17.0) (3.16.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.17.0) (4.66.5)\n",
            "Collecting ibm-cos-sdk-core==2.13.6 (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning==1.0.349)\n",
            "  Downloading ibm-cos-sdk-core-2.13.6.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cos-sdk-s3transfer==2.13.6 (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning==1.0.349)\n",
            "  Downloading ibm-cos-sdk-s3transfer-2.13.6.tar.gz (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<=1.0.1,>=0.10.0 (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning==1.0.349)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.9.0 (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning==1.0.349)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting requests (from ibm-watson-machine-learning==1.0.349)\n",
            "  Downloading requests-2.32.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.17.0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.17.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.17.0) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.17.0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.17.0) (3.1.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.17.0) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.17.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.17.0) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ibm-watson-machine-learning==1.0.349) (3.3.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.17.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.17.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.17.0) (13.8.1)\n",
            "\u001b[33mWARNING: typer 0.12.5 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting h11>=0.8 (from uvicorn>=0.14.0->gradio==4.17.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio==4.17.0)\n",
            "  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==4.17.0) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->gradio==4.17.0)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==4.17.0) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->ibm-watson-machine-learning==1.0.349) (3.20.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from lomond->ibm-watson-machine-learning==1.0.349) (1.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.17.0) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.17.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.17.0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.17.0) (0.20.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.17.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.17.0) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==4.17.0) (1.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.17.0) (0.1.2)\n",
            "Downloading gradio-4.17.0-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_watson_machine_learning-1.0.349-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Downloading gradio_client-0.9.0-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.114.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
            "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.13.6-py3-none-any.whl size=77230 sha256=72343689b4f6382e0ee5993de244ebf3ecb86d06da3cbeae14b8c375d31e8fc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/c7/ef/c6899afa27e0f60b856525da93758d16b52be89d54852ae906\n",
            "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.13.6-py3-none-any.whl size=661457 sha256=80e43d75ffb7d951b1efd69811ddb06ba09dc712f8145ff8189480734a95d505\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/6e/9b/27f10308c37a531ffb880add20d61753ca3b2c24034f4530da\n",
            "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.13.6-py3-none-any.whl size=90206 sha256=77a0ae9e040b879cb31d7fe0ed70b21fe55fb5edd2d5a89cc57f5efac5eb9abb\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/11/8e/5cc3f2d57d16951d4a7b15995338e3bd21b71cded6b9494fb2\n",
            "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
            "Installing collected packages: pydub, websockets, tomlkit, semantic-version, ruff, requests, python-multipart, python-dateutil, orjson, lomond, jmespath, h11, ffmpy, dnspython, aiofiles, uvicorn, starlette, pandas, ibm-cos-sdk-core, httpcore, email-validator, ibm-cos-sdk-s3transfer, httpx, fastapi, ibm-cos-sdk, gradio-client, ibm-watson-machine-learning, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.2\n",
            "    Uninstalling tomlkit-0.13.2:\n",
            "      Successfully uninstalled tomlkit-0.13.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.2 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email-validator-2.1.1 fastapi-0.114.2 ffmpy-0.4.0 gradio-4.17.0 gradio-client-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 ibm-cos-sdk-2.13.6 ibm-cos-sdk-core-2.13.6 ibm-cos-sdk-s3transfer-2.13.6 ibm-watson-machine-learning-1.0.349 jmespath-1.0.1 lomond-0.3.3 orjson-3.10.7 pandas-1.5.3 pydub-0.25.1 python-dateutil-2.9.0.post0 python-multipart-0.0.9 requests-2.32.2 ruff-0.6.5 semantic-version-2.10.0 starlette-0.38.5 tomlkit-0.12.0 uvicorn-0.30.6 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              },
              "id": "69dc9357acec44e3b7df2dbfc83d3c33"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install gradio==4.17.0 ibm-watson-machine-learning==1.0.349 email-validator==2.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a simple LLM using Gradio UI and Meta's llama-2-70b-chat LLM\n",
        "# Might not run here, only runs in IBM Development Environment\n",
        "\n",
        "# Import necessary packages\n",
        "from ibm_watson_machine_learning.foundation_models import Model\n",
        "import gradio as gr\n",
        "\n",
        "# Set credentials to use the model\n",
        "my_credentials = {\n",
        "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
        "}\n",
        "\n",
        "# Model and project settings\n",
        "model_id = \"meta-llama/llama-2-70b-chat\"  # Directly specifying the LLAMA2 model\n",
        "project_id = \"skills-network\"  # Specifying project_id as provided\n",
        "space_id = None\n",
        "verify = False\n",
        "gen_parms = {\n",
        "        \"max_new_tokens\": 512,\n",
        "        \"temperature\": 0.1\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "model = Model(model_id, my_credentials, gen_parms, project_id, space_id, verify)\n",
        "\n",
        "# Function to generate a response from the model\n",
        "def generate_response(prompt_txt):\n",
        "    generated_response = model.generate(prompt_txt)\n",
        "\n",
        "    # Extract and return the generated text\n",
        "    generated_text = generated_response[\"results\"][0][\"generated_text\"]\n",
        "    return generated_text\n",
        "\n",
        "# Create Gradio interface\n",
        "chat_application = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    allow_flagging=\"never\",\n",
        "    inputs=gr.Textbox(label=\"Input\", lines=2, placeholder=\"Type your question here...\"),\n",
        "    outputs=gr.Textbox(label=\"Output\"),\n",
        "    title=\"Watsonx.ai Chatbot\",\n",
        "    description=\"Ask any question and the chatbot will try to answer.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "chat_application.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "V-8sq3418v3J",
        "outputId": "f01b65be-8d1b-476c-a606-bf016ba5e593"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ibm_watson_machine_learning.wml_client_error:'`apikey` for IAM token is not provided in credentials for the client'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WMLClientError",
          "evalue": "'`apikey` for IAM token is not provided in credentials for the client'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b459f3ef997b>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Initialize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_credentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_parms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Function to generate a response from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ibm_watson_machine_learning/foundation_models/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_id, credentials, params, project_id, space_id, verify)\u001b[0m\n\u001b[1;32m     80\u001b[0m                  \u001b[0mspace_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                  verify=None) -> None:\n\u001b[0;32m---> 82\u001b[0;31m         ModelInference.__init__(self,\n\u001b[0m\u001b[1;32m     83\u001b[0m                                 \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                                 \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ibm_watson_machine_learning/foundation_models/inference/model_inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAPIClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ibm_watson_machine_learning/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wml_credentials, project_id, verify)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_IAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apikey_not_provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             if 'icp' == self.wml_credentials[u'instance_id'].lower() or 'openshift' == self.wml_credentials[\n",
            "\u001b[0;31mWMLClientError\u001b[0m: '`apikey` for IAM token is not provided in credentials for the client'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resume Polisher\n",
        "\n",
        "# Import necessary packages\n",
        "from ibm_watson_machine_learning.foundation_models import Model\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "model_id = \"meta-llama/llama-2-70b-chat\"  # Directly specifying the LLAMA2 model\n",
        "\n",
        "# Set credentials to use the model\n",
        "my_credentials = {\n",
        "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
        "}\n",
        "\n",
        "# Generation parameters\n",
        "gen_parms = {\n",
        "    \"max_new_tokens\": 512,  # Increased token limit for larger content\n",
        "    \"temperature\": 0.7  # Adjusted for more creative variations\n",
        "}\n",
        "project_id = \"skills-network\"  # Specifying project_id as provided\n",
        "space_id = None\n",
        "verify = False\n",
        "\n",
        "# Initialize the model\n",
        "model = Model(model_id, my_credentials, gen_parms, project_id, space_id, verify)\n",
        "\n",
        "# Function to polish the resume using the model, making polish_prompt optional\n",
        "def polish_resume(position_name, resume_content, polish_prompt=\"\"):\n",
        "    # Check if polish_prompt is provided and adjust the combined_prompt accordingly\n",
        "    if polish_prompt and polish_prompt.strip():\n",
        "        prompt_use = f\"Given the resume content: '{resume_content}', polish it based on the following instructions: {polish_prompt} for the {position_name} position.\"\n",
        "    else:\n",
        "        prompt_use = f\"Suggest improvements for the following resume content: '{resume_content}' to better align with the requirements and expectations of a {position_name} position. Return the polished version, highlighting necessary adjustments for clarity, relevance, and impact in relation to the targeted role.\"\n",
        "\n",
        "    # Generate a response using the model with parameters\n",
        "    generated_response = model.generate(prompt_use)\n",
        "\n",
        "    # Extract and return the generated text\n",
        "    generated_text = generated_response[\"results\"][0][\"generated_text\"]\n",
        "    return generated_text\n",
        "\n",
        "# Create Gradio interface for the resume polish application, marking polish_prompt as optional\n",
        "resume_polish_application = gr.Interface(\n",
        "    fn=polish_resume,\n",
        "    allow_flagging=\"never\", # Deactivate the flag function in gradio as it is not needed.\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Position Name\", placeholder=\"Enter the name of the position...\"),\n",
        "        gr.Textbox(label=\"Resume Content\", placeholder=\"Paste your resume content here...\", lines=20),\n",
        "        gr.Textbox(label=\"Polish Instruction (Optional)\", placeholder=\"Enter specific instructions or areas for improvement (optional)...\", lines=2),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Polished Content\"),\n",
        "    title=\"Resume Polish Application\",\n",
        "    description=\"This application helps you polish your resume. Enter the position your want to apply, your resume content, and specific instructions or areas for improvement (optional), then get a polished version of your content.\"\n",
        ")\n",
        "\n",
        "# Launch the application\n",
        "resume_polish_application.launch()"
      ],
      "metadata": {
        "id": "6cv6Nl1fMkI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Cover Letter According To The Job Description And Your Resume\n",
        "\n",
        "# Import necessary packages\n",
        "from ibm_watson_machine_learning.foundation_models import Model\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "# Model and project settings\n",
        "model_id = \"meta-llama/llama-2-70b-chat\"  # Directly specifying the LLAMA2 model\n",
        "\n",
        "# Set credentials to use the model\n",
        "my_credentials = {\n",
        "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
        "}\n",
        "\n",
        "# Generation parameters\n",
        "gen_parms = {\n",
        "    \"max_new_tokens\": 512,  # Adjust as needed for the length of the cover letter\n",
        "    \"temperature\": 0.7  # Adjust for creativity\n",
        "}\n",
        "project_id = \"skills-network\"\n",
        "space_id = None\n",
        "verify = False\n",
        "\n",
        "# Initialize the model\n",
        "model = Model(model_id, my_credentials, gen_parms, project_id, space_id, verify)\n",
        "\n",
        "# Function to generate a customized cover letter\n",
        "def generate_cover_letter(company_name, position_name, job_description, resume_content):\n",
        "    # Craft the prompt for the model to generate a cover letter\n",
        "    prompt = f\"Generate a customized cover letter using the company name: {company_name}, the position applied for: {position_name}, and the job description: {job_description}. Ensure the cover letter highlights my qualifications and experience as detailed in the resume content: {resume_content}. Adapt the content carefully to avoid including experiences not present in my resume but mentioned in the job description. The goal is to emphasize the alignment between my existing skills and the requirements of the role.\"\n",
        "\n",
        "    generated_response = model.generate(prompt, gen_parms)\n",
        "\n",
        "    # Extract the generated text\n",
        "    cover_letter = generated_response[\"results\"][0][\"generated_text\"]\n",
        "    return cover_letter\n",
        "\n",
        "# Create Gradio interface for the cover letter generation application\n",
        "cover_letter_app = gr.Interface(\n",
        "    fn=generate_cover_letter,\n",
        "    allow_flagging=\"never\", # Deactivate the flag function in gradio as it is not needed.\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Company Name\", placeholder=\"Enter the name of the company...\"),\n",
        "        gr.Textbox(label=\"Position Name\", placeholder=\"Enter the name of the position...\"),\n",
        "        gr.Textbox(label=\"Job Description Information\", placeholder=\"Paste the job description here...\", lines=10),\n",
        "        gr.Textbox(label=\"Resume Content\", placeholder=\"Paste your resume content here...\", lines=10),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Customized Cover Letter\"),\n",
        "    title=\"Customized Cover Letter Generator\",\n",
        "    description=\"Generate a customized cover letter by entering the company name, position name, job description and your resume.\"\n",
        ")\n",
        "\n",
        "# Launch the application\n",
        "cover_letter_app.launch()"
      ],
      "metadata": {
        "id": "QcyAICk7NbYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Career Advisor\n",
        "\n",
        "# Import necessary packages\n",
        "from ibm_watson_machine_learning.foundation_models import Model\n",
        "import gradio as gr\n",
        "\n",
        "# Model and project settings\n",
        "model_id = \"meta-llama/llama-2-70b-chat\"  # Directly specifying the LLAMA2 model\n",
        "\n",
        "# Set credentials\n",
        "my_credentials = {\n",
        "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
        "}\n",
        "\n",
        "# Generation parameters\n",
        "gen_parms = {\n",
        "    \"max_new_tokens\": 1024,  # Adjust as needed\n",
        "    \"temperature\": 0.7  # Adjust for creativity\n",
        "}\n",
        "\n",
        "project_id = \"skills-network\"  # Use this project_id\n",
        "space_id = None\n",
        "verify = False\n",
        "\n",
        "# Initialize the model with the correct parameters\n",
        "model = Model(model_id, my_credentials, gen_parms, project_id, space_id, verify)\n",
        "\n",
        "# Function to generate career advice\n",
        "def generate_career_advice(position_applied, job_description, resume_content):\n",
        "    # The prompt for the model\n",
        "    prompt = f\"Considering the job description: {job_description}, and the resume provided: {resume_content}, identify areas for enhancement in the resume. Offer specific suggestions on how to improve these aspects to better match the job requirements and increase the likelihood of being selected for the position of {position_applied}.\"\n",
        "\n",
        "    # Generate response\n",
        "    generated_response = model.generate(prompt, gen_parms)\n",
        "\n",
        "    # Extract and format the generated text\n",
        "    advice = generated_response[\"results\"][0][\"generated_text\"]\n",
        "    return advice\n",
        "\n",
        "# Create Gradio interface for the career advice application\n",
        "career_advice_app = gr.Interface(\n",
        "    fn=generate_career_advice,\n",
        "    allow_flagging=\"never\", # Deactivate the flag function in gradio as it is not needed.\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Position Applied For\", placeholder=\"Enter the position you are applying for...\"),\n",
        "        gr.Textbox(label=\"Job Description Information\", placeholder=\"Paste the job description here...\", lines=10),\n",
        "        gr.Textbox(label=\"Your Resume Content\", placeholder=\"Paste your resume content here...\", lines=10),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Advice\"),\n",
        "    title=\"Career Advisor\",\n",
        "    description=\"Enter the position you're applying for, paste the job description, and your resume content to get advice on what to improve for getting this job.\"\n",
        ")\n",
        "\n",
        "# Launch the application\n",
        "career_advice_app.launch()"
      ],
      "metadata": {
        "id": "IufkAKHLO09F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acPkAyYdO2m3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}